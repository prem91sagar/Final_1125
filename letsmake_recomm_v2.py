# -*- coding: utf-8 -*-
"""LetsMake_recomm_v2.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1BWuw6pGLKkYTYcCUxHRyQJGxytvnZ0_P
"""

import pandas as pd
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import linear_kernel

df = pd.read_csv('updated_data_1C_v4.csv')
# Replace NaN with an empty string
df['Description'] = df['Description'].fillna('')
print (df)

# Create a TfidfVectorizer and Remove stopwords
tfidf = TfidfVectorizer()
# Fit and transform the data to a tfidf matrix
tfidf_matrix = tfidf.fit_transform(df['Description'])
# Print the shape of the tfidf_matrix
tfidf_matrix.shape

# Compute the cosine similarity between each movie description
cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)

indices = pd.Series(df.index, index=df['Sensor']).drop_duplicates()
type (indices)
indices.keys()

def get_recommendations(Sensor, cosine_sim=cosine_sim, num_recommend = 20):
    idx = indices[Sensor]
# Get the pairwsie similarity scores 
    sim_scores = list(enumerate(cosine_sim[idx]))
# Sort on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
# Get the scores of the 10 most similar 
    top_similar = sim_scores[1:num_recommend+1]
# Get the indices
    m_indices = [i[0] for i in top_similar]
# Return the top 10 most similar movies
    #return df['Sensor'].iloc[movie_indices]
    #df['Sensor'].iloc[movie_indices]
#df
    return df['Description'].iloc[m_indices]
    df['Description'].iloc[m_indices]
df

#for each word in output of word to vec:
    #for each keyword in database:
      #if word = keyword:
        #Then for index of keyword
        #get index in column of associated sensor
        #return column
      #else:
        #pass

  #for loops




#_____________________other optiopn
        #.find() maybe use this

get_recommendations('Temp', num_recommend = 1)