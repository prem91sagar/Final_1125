# -*- coding: utf-8 -*-
"""nltk_dist.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1a2e59pM6cVaC8TLLTO3gjUnWKUJWqyJS
"""

!pip install rake_nltk
import rake_nltk

import nltk
nltk.download('stopwords')
import nltk
nltk.download('punkt')

text = input("")

import pandas as pd

from rake_nltk import Rake
rake_nltk_var = Rake()

rake_nltk_var.extract_keywords_from_text(text)
k_e = rake_nltk_var.get_ranked_phrases()
kf=pd.DataFrame(k_e)
kf
#S = keyword_extracted
#S

#pd.read_csv("l.csv") ilock
#string type

k = pd.read_csv('updated_data_1C.csv', usecols=[1]) 
k
df= pd.DataFrame(k)
print (df)
#serie = k.transpose()[0]
#serie

#rake_nltk_var.extract_keywords_from_text(df)
#keyword_extractedk = rake_nltk_var.get_ranked_phrases()

#df = pd.read_csv("updated_data_1C.csv", usecols=[1]) 
   
# output the dataframe
#print(df1)

#df = k[].merge(df1[], left_index=True, right_index=True, suffixes=('_1', '_2'))
df1= pd.DataFrame(df)

from nltk.metrics import edit_distance
nltk.metrics.distance.edit_distance_align(df, kf)

df2_merged = df1.merge(kf)

# Compute the Levenshtein distance
df['distance'] = df.apply(lambda x: levenshtein.distance(x['SAX_1'],  x['SAX_2']), axis=1)

results = df.loc[:, ["df", "S"]].apply(lambda x: edit_distance(*x), axis=1)

#string decleration
source= 'tomato hot'
#target= 'k'
#distance calculation
distance1=nltk.edit_distance(source,'k')

#distance[]=nltk.edit_distance('S[1]]','k[1]')
#distance[]=nltk.edit_distance('S[]','k[]')
print(distance2)

sim_scores = list(enumerate(cosine_sim[idx]))
# Sort the movies based on the similarity scores
    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)
# Get the scores of the 10 most similar movies
    top_similar = sim_scores[1:num_recommend+1]
# Get the movie indices
    movie_indices = [i[0] for i in top_similar]

for loop array then i in a
I= 1VALUES
if i in